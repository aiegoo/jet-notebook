{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2, time\n",
    "from jetbot import Camera\n",
    "from jetbot import bgr8_to_jpeg\n",
    "import ipywidgets.widgets as widgets\n",
    "import traitlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(img):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "    gray = cv2.GaussianBlur(gray, (7,7),0)\n",
    "    return gray\n",
    "\n",
    "def thresholding(img_gray):\n",
    "    _, img_th = cv2.threshold(img_gray,np.average(img_gray)-40,255,cv2.THRESH_BINARY)\n",
    "    img_th2 = cv2.adaptiveThreshold(img_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,21,15)\n",
    "    img_th3 = np.bitwise_and(img_th, img_th2)\n",
    "    img_th4 = cv2.subtract(img_th2, img_th3)\n",
    "    for i in range(5):\n",
    "        img_th4 = cv2.medianBlur(img_th4, 5)\n",
    "    return img_th4\n",
    "\n",
    "def mask_roi(img_th, roi):\n",
    "    mask = np.zeros_like(img_th)\n",
    "    cv2.fillPoly(mask, np.array([roi], np.int32), 255)\n",
    "    masked_image = cv2.bitwise_and(img_th, mask)\n",
    "    return masked_image\n",
    "\n",
    "def drawContours(img_rgb, contours):\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        cv2.drawContours(img_rgb, [cnt], 0, (255,0,0), 1)\n",
    "    return img_rgb\n",
    "\n",
    "def approximationContour(img, contours, e=0.02):\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        epsilon = e*cv2.arcLength(cnt, True)\n",
    "        approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "        cv2.drawContours(img, [approx], 0, (0,255,255), 2)\n",
    "    return img\n",
    "\n",
    "def rectwithname(img, contours, e=0.02):\n",
    "    result = img.copy()\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        epsilon = e*cv2.arcLength(cnt, True)\n",
    "        approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "        cv2.rectangle(result,(x,y),(x+w,y+h),(255,0,255),2)\n",
    "    return result\n",
    "\n",
    "def find_midptr(contours):\n",
    "    center_ptrs = []\n",
    "    e=0.01\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        center_ptr = [y, x + 0.5*w,]\n",
    "        center_ptrs.append(center_ptr)\n",
    "    center_ptrs = np.array(center_ptrs)\n",
    "    return center_ptrs\n",
    "\n",
    "def find_midlane(center_ptrs, center_image_point):\n",
    "    L2_norm = np.linalg.norm((center_ptrs - center_image_point), axis=1, ord=2)\n",
    "    loc = np.where(L2_norm==L2_norm.min())[0][0]\n",
    "    midlane = center_ptrs[loc]\n",
    "    return midlane\n",
    "\n",
    "def find_degree(center_image_point, midlane):\n",
    "    return 57.2958*np.arctan((midlane[1] - center_image_point[1])/(center_image_point[0] - midlane[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564e8c64958c4645886ada58eb92a0c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'', format='jpeg', height='224', width='224'), Image(value=b'', format='jpeg', heiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "width = 224\n",
    "height = 224\n",
    "camera = Camera.instance()\n",
    "input_image = widgets.Image(format='jpeg', width=width, height=height)\n",
    "result1 = widgets.Image(format='jpeg', width=width, height=height)\n",
    "result2 = widgets.Image(format='jpeg', width=width, height=height)\n",
    "result3 = widgets.Image(format='jpeg', width=width, height=height)\n",
    "result4 = widgets.Image(format='jpeg', width=width, height=height)\n",
    "image_box = widgets.HBox([input_image, result1, result2, result3, result4], layout=widgets.Layout(align_self='center'))\n",
    "display(image_box)\n",
    "# display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-c93a7ff23925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#         print(count, end='  ')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "while True:\n",
    "    img = camera.value\n",
    "    img_gray = preprocessing(img)\n",
    "    img_th = thresholding(img_gray)\n",
    "    roi = [(0, height),(0, height/2-30), (width, height/2-30),(width, height),]\n",
    "    img_roi = mask_roi(img_th, roi)\n",
    "    \n",
    "    kernel = np.ones((5,3),np.uint8)\n",
    "    img_cl = cv2.morphologyEx(img_roi,cv2.MORPH_CLOSE, np.ones((5,5),np.uint8),iterations=4)\n",
    "    img_op = cv2.morphologyEx(img_cl,cv2.MORPH_OPEN, np.ones((5,5),np.uint8),iterations=3)\n",
    "    \n",
    "    cannyed_image = cv2.Canny(img_op, 300, 500)\n",
    "    contours, _ = cv2.findContours(cannyed_image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    img_approx = approximationContour(img, contours, e=0.02)\n",
    "    img_approx_rect = rectwithname(img, contours, e=0.01)  \n",
    "    \n",
    "    center_ptrs = find_midptr(contours)\n",
    "    \n",
    "    center_image_point = [height-1, width/2-1]\n",
    "        \n",
    "    midlane = find_midlane(center_ptrs, center_image_point)\n",
    "    seta = find_degree(center_image_point, midlane)\n",
    "    \n",
    "    cv2.line(img,(int(center_image_point[1]), int(center_image_point[0])),(int(midlane[1]),int(midlane[0])),(0,0,255),3)\n",
    "    cv2.putText(img, f'{seta}', (int(midlane[1]), int(midlane[0])-5), cv2.FONT_HERSHEY_COMPLEX, 0.5,(255, 0, 0), 1)\n",
    "    \n",
    "    result_img1 = img_th\n",
    "    result_img2 = img_cl\n",
    "    result_img3 = img_op\n",
    "    result_img4 = img\n",
    "    \n",
    "    #show results\n",
    "    result_imgs = [result_img1, result_img2, result_img3, result_img4]\n",
    "    result_values = [result1, result2, result3, result4]\n",
    "    for result_img, result_value in zip(result_imgs, result_values):\n",
    "#         if len(result_img.shape)==2:\n",
    "#             result_img = np.stack((result_img,)*3,2)\n",
    "        result_value.value = bgr8_to_jpeg(result_img)\n",
    "    input_image.value = bgr8_to_jpeg(img_gray)\n",
    "    \n",
    "    if count ==1000:\n",
    "        break\n",
    "    else:\n",
    "        count = count +1\n",
    "#         print(count, end='  ')\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_road(img):\n",
    "    img_gray = preprocessing(img)\n",
    "    img_th = thresholding(img_gray)\n",
    "    roi = [(0, height),(0, height/2-30), (width, height/2-30),(width, height),]\n",
    "    img_roi = mask_roi(img_th, roi)\n",
    "    \n",
    "    kernel = np.ones((5,3),np.uint8)\n",
    "    img_cl = cv2.morphologyEx(img_roi,cv2.MORPH_CLOSE, np.ones((5,5),np.uint8),iterations=4)\n",
    "    img_op = cv2.morphologyEx(img_cl,cv2.MORPH_OPEN, np.ones((5,5),np.uint8),iterations=3)\n",
    "    \n",
    "    cannyed_image = cv2.Canny(img_op, 300, 500)\n",
    "    contours, _ = cv2.findContours(cannyed_image, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    center_ptrs = find_midptr(contours)\n",
    "\n",
    "    center_image_point = [height-1, width/2-1]\n",
    "    midlane = find_midlane(center_ptrs, center_image_point)\n",
    "    seta = find_degree(center_image_point, midlane)\n",
    "    \n",
    "    cv2.line(img,(int(center_image_point[1]), int(center_image_point[0])),(int(midlane[1]),int(midlane[0])),(0,0,255),3)\n",
    "    cv2.putText(img, f'{seta}', (int(midlane[1]), int(midlane[0])-5), cv2.FONT_HERSHEY_COMPLEX, 0.5,(255, 0, 0), 1)\n",
    "    return img, seta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "while True:\n",
    "    img = camera.value\n",
    "    img_result, seta = search_road(img)\n",
    "    \n",
    "    input_image.value = bgr8_to_jpeg(img_gray)\n",
    "    result1.value = bgr8_to_jpeg(img_result)\n",
    "    if count ==20:\n",
    "        break\n",
    "    else:\n",
    "        count = count +1\n",
    "#         print(count, end='  ')\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
